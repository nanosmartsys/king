{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PERSISTENCE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nanosmartsys/king/blob/main/PERSISTENCE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo 'Mounting...'\n",
        "from google.colab import drive\n",
        "drive.mount('...') # include your drive path \n",
        "!ls '...' # include your drive path \n",
        "!echo 'Mounted'"
      ],
      "metadata": {
        "id": "83spohVdxyHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "NZ79h7h-8skC"
      },
      "outputs": [],
      "source": [
        "#@title Persistence Model \n",
        "import numpy as np\n",
        "\n",
        "# Reduce randomness in model outputs\n",
        "np.random.seed(1)\n",
        "\n",
        "from matplotlib import pyplot\n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "from keras.models import load_model\n",
        "import pandas as pd\n",
        "from pandas import concat\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from numpy import concatenate\n",
        "from scipy.stats import boxcox\n",
        "from math import exp\n",
        "from math import log\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from numpy import array\n",
        "# %matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import sys\n",
        "\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "\n",
        "# invert a boxcox transform for one value\n",
        "def invert_boxcox(value, lam):\n",
        "  # log case\n",
        "  if lam == 0:\n",
        "    return exp(value)\n",
        "  # all other cases\n",
        "  return exp(log(lam * value + 1) / lam)\n",
        "\n",
        "# evaluate a single model\n",
        "def evaluate_model(n_train_input,n_train_output,n_test_input,n_test_output):\n",
        "  # history is a list of hourly data\n",
        "  predictions = list()\n",
        "  actuals = list()\n",
        "  for_val = n_train_input[-1]\n",
        "  predictions.append(for_val[-1])\n",
        "  actuals.append(n_train_output[-1]) \n",
        "      \n",
        "\t# walk-forward validation over each hour\n",
        "  for i in range(len(n_test_input)):\n",
        "\t\t# predict the hour    \n",
        "    yhat_sequence = n_test_input[i]\n",
        "\t\t# store the predictions   \n",
        "    predictions.append(yhat_sequence[-1])\n",
        "\t\t# get real observation and add to history for predicting the next hour\n",
        "    actuals.append(n_test_output[i])  \n",
        "  predictions = array(predictions)\n",
        "  actuals = array(actuals)\n",
        "  return predictions,actuals\n",
        "  \n",
        "#Load county data\n",
        "mydata = pd.read_csv('nas.csv', header=0)\n",
        "dataIn = mydata[mydata.columns[1:8]] \n",
        "dateT = mydata[mydata.columns[0]]\n",
        "dateT = DataFrame(dateT)\n",
        "dateT['dateTime'] = dateT\n",
        "dateT.drop('Unnamed: 0', axis = 1, inplace = True)\n",
        "df_data = pd.concat((dateT, dataIn), axis=1)\n",
        "df_data = df_data.drop(df_data.columns[0], axis = 1)\n",
        "\n",
        "# Interpolate missing values\n",
        "df_data = df_data.interpolate(method ='linear', limit_direction ='both', limit = 10000, axis=0)\n",
        "\n",
        "# Split into train and test set\n",
        "train_size = int(len(df_data) * 0.8)\n",
        "train_data, test_data = df_data[0:train_size], df_data[train_size:]\n",
        "\n",
        "\n",
        "# Historical data\n",
        "df_data_train = pd.DataFrame(train_data,columns=['Temp','Preci','Gust','Wind','Windir','LAI','Total Outages'])\n",
        "# Test data\n",
        "df_data_test = pd.DataFrame(test_data,columns=['Temp','Preci','Gust','Wind','Windir','LAI','Total Outages'])\n",
        "\n",
        "# power transform target variable to be gausian like - TRAIN\n",
        "box_power =df_data_train['Total Outages'] \n",
        "transformed, lmbda = boxcox(box_power)  \n",
        "##df_data_train['Total Outages'] = transformed\n",
        "df_trans_train = np.array(transformed)\n",
        "df_trans_train = df_trans_train.reshape(-1,1)\n",
        "\n",
        "# power transform target variable to be gausian like - TEST\n",
        "box_power_test =df_data_test['Total Outages'] \n",
        "transformed_test = boxcox(box_power_test,lmbda)  \n",
        "##df_data_test['Total Outages'] = transformed_test\n",
        "df_trans_test = np.array(transformed_test)\n",
        "df_trans_test = df_trans_test.reshape(-1,1)\n",
        "\n",
        "# Smoothed target series peaks with rolling average. This is to reduce noise effect in the data\n",
        "# Training fold            \n",
        "dwAvg = 6 # 6hrs rolling average\n",
        "y_train = pd.DataFrame(df_trans_train)\n",
        "y_train = y_train.rolling(dwAvg).mean()\n",
        "y_train = y_train.interpolate(method ='linear', limit_direction ='both', limit = 100, axis=0) \n",
        "# Test fold            \n",
        "y_test = pd.DataFrame(df_trans_test)\n",
        "y_test = y_test.rolling(dwAvg).mean()\n",
        "y_test = y_test.interpolate(method ='linear', limit_direction ='both', limit = 100, axis=0)\n",
        "\n",
        "# Scaling\n",
        "# Train\n",
        "Y_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "Y_train_scaled_data = Y_scaler.fit_transform(y_train)\n",
        "# Test\n",
        "Y_test_scaled_data = Y_scaler.transform(y_test)\n",
        "\n",
        "# Build history of time series\n",
        "start = 0  \n",
        "lag = 6 # look back\n",
        "h = 6   # horizon\n",
        "y_tr_input= list()\n",
        "y_tr_output= list()\n",
        "train_data_value = Y_train_scaled_data\n",
        "\n",
        "end = None\n",
        "start = start + lag\n",
        "if end is None:\n",
        "  end = len(Y_train_scaled_data) - h\n",
        "for i in range(start, end):\n",
        "  indices = range(i-lag, i)\n",
        "  y_tra_input = train_data_value[indices]    \n",
        "  indicey = range(i+1, i+1+h)\n",
        "  y_tra_output = train_data_value[indicey]\n",
        "  y_tr_input.append(y_tra_input)\n",
        "  y_tr_output.append(y_tra_output)\n",
        "\n",
        "\n",
        "# Prepare test data\n",
        "start = 0\n",
        "y_te_input= list()\n",
        "y_te_output= list()\n",
        "test_data_value = Y_test_scaled_data\n",
        "\n",
        "last = None\n",
        "start = start + lag\n",
        "if last is None:\n",
        "  last = len(Y_test_scaled_data) - h\n",
        "for j in range(start, last, lag):\n",
        "  indices_j = range(j-lag, j)\n",
        "  ##print(list(indices_j))\n",
        "  y_tes_input = test_data_value[indices_j]    \n",
        "  indicey_j = range(j+1, j+1+h)\n",
        "  ##print(list(indicey_j))\n",
        "  y_tes_output = test_data_value[indicey_j]\n",
        "  y_te_input.append(y_tes_input)\n",
        "  y_te_output.append(y_tes_output)  \n",
        "\n",
        "y_train_input = np.array(y_tr_input)\n",
        "y_test_input = np.array(y_te_input)\n",
        "\n",
        "y_train_output_reshaped = np.array(y_tr_output)\n",
        "y_test_output_reshaped = np.array(y_te_output)\n",
        "\n",
        "y_train_output = y_train_output_reshaped.reshape(y_train_output_reshaped.shape[0],y_train_output_reshaped.shape[1]*1)\n",
        "y_train_output = y_train_output[:,-1]\n",
        "\n",
        "y_test_output = y_test_output_reshaped.reshape(y_test_output_reshaped.shape[0],y_test_output_reshaped.shape[1]*1)\n",
        "y_test_output = y_test_output[:,-1]\n",
        "\n",
        "# Print input and output smaples\n",
        "print(y_train_input.shape,y_train_output.shape)\n",
        "print(y_test_input.shape,y_test_output.shape)\n",
        "\n",
        "# Compute RMSE\n",
        "y_pred, y_actual = evaluate_model(y_train_input,y_train_output,y_test_input,y_test_output)\n",
        "y_p = y_pred.reshape(y_pred.shape[0],1)\n",
        "y_ac = y_actual.reshape(-1,1)\n",
        "y_last_h = y_p \n",
        "pred_Inverse = Y_scaler.inverse_transform(y_last_h)\n",
        "# Inverse power transform of forecast values\n",
        "y_b_inv = [invert_boxcox(x, lmbda) for x in pred_Inverse]\n",
        "y_b_inv = np.array(y_b_inv)\n",
        "# Inverse power transform of actual values\n",
        "actual_Inverse = Y_scaler.inverse_transform(y_ac)\n",
        "y_actual_inv = [invert_boxcox(x, lmbda) for x in actual_Inverse]\n",
        "y_actual_inv = np.array(y_actual_inv)\n",
        "\n",
        "pred = y_b_inv\n",
        "actual = y_actual_inv[-len(pred):]\n",
        "\n",
        "mse = mean_squared_error(actual, pred)\n",
        "# calculate rmse\n",
        "rmse = sqrt(mse)  \n",
        "# print rmse\n",
        "print('Average Test RMSE: %.3f' % (rmse))\n",
        "\n",
        "# Visualizations\n",
        "fig, axes = pyplot.subplots(2, 1, figsize=(12, 8))\n",
        "fig.tight_layout(pad=6.0)\n",
        "\n",
        "axes[0].set_title(\"Actual & forecasted test samples\")\n",
        "axes[0].set_xlabel(\"Time Step\")\n",
        "axes[0].set_ylabel(\"Customer Outages\")\n",
        "\n",
        "real = DataFrame(actual)\n",
        "real = real.values\n",
        "\n",
        "x_axis = np.arange(train_data.shape[0] + pred.shape[0])\n",
        "axes[0].plot(x_axis[:train_data.shape[0]], train_data, alpha=0.75,label='Train Data')\n",
        "axes[0].legend(loc=\"upper right\")\n",
        "axes[0].scatter(x_axis[train_data.shape[0]:], pred, alpha=0.4, marker='o',label='Forecast')\n",
        "axes[0].legend(loc=\"upper right\")\n",
        "axes[0].scatter(x_axis[train_data.shape[0]:], actual[-len(pred):], alpha=0.4, marker='x',label='Test Data')\n",
        "axes[0].legend(loc=\"upper right\")\n",
        "\n",
        "new_x_axis = np.arange(300)\n",
        "axes[1].plot(new_x_axis[:real.shape[0]], real[:300], alpha=0.75,label='Actual')\n",
        "axes[1].legend(loc=\"upper right\")\n",
        "axes[1].plot(new_x_axis[:real.shape[0]], pred[:300], alpha=0.4,label='Predicted')\n",
        "axes[1].legend(loc=\"upper right\")\n",
        "axes[1].set_title(\"Actual & forecasted test samples:First 300 time steps in expanded view\")\n",
        "axes[1].set_xlabel(\"Time Step\")\n",
        "axes[1].set_ylabel(\"Customer Outages\")\n",
        "pyplot.show()"
      ]
    }
  ]
}